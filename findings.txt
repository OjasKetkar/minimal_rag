Step - added token constraint
common question - tell me about ojas:
max tokens = 
1. 1000 -> Ojas Ketkar is a final-year Computer Science undergraduate student at Vishwakarma Institute of
2. 2000 -> Ojas Ketkar is a final-year Computer Science undergraduate student at Vishwakarma Institute of Technology
3. 3000 -> Ojas Ketkar is a final-year Computer Science undergraduate student at Vishwakarma Institute


now when we added chunk-prioritization : 
The above findings fail since we are now addding more relevant chunks of data to the memory
So k=10k with chunk-prior. gave me a shorter answer, but with more certainty than k=2k without chunk prior.